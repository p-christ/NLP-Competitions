{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification (Kaggle) - Simple Baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_PTaklxgTzA",
        "colab_type": "text"
      },
      "source": [
        "#Toxic Comment Classification (Kaggle) - Simple Baseline\n",
        "\n",
        "Simple baseline model for the [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/rules) that uses Glove embeddings and a bidirectional GRU with Tensorflow 2.0\n",
        "\n",
        "Likely ways to further improve the model:\n",
        "\n",
        "\n",
        "*   Use an embedding method that takes into account the context of the sentence e.g. BERT\n",
        "*   Use optimisation tricks like a circular learning rate schedule\n",
        "*   Try using an attention-based architecture\n",
        "*   Try different forms of pre-processing, e.g. removing stop words like \"the\"\n",
        "*   Increase the allowed max length of sequence\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOaCpe6keHze",
        "colab_type": "code",
        "outputId": "abee88c2-9bfa-41c3-ed10-57fd4d7876f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install tensorflow==2.0 -q\n",
        "!pip install tensorflow-gpu==2.0 -q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 69.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 30.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 43.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 380.8MB 124kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtSMpWrdeDdX",
        "colab_type": "code",
        "outputId": "8a9f362c-337b-4a02-a69b-d4862e9214dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import drive \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 0\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOkCkR0PZNSo",
        "colab_type": "text"
      },
      "source": [
        "#1. Download and Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrrP4AhpiWga",
        "colab_type": "code",
        "outputId": "3969d303-9d6f-42b3-d1df-f117c8d2205d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Download the data\n",
        "#Replace these lines with paths to the data for the competition which can be found here: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
        "DRIVE_FOLDER = '/content/drive/My Drive/Toxic_Comment_Classification_Kaggle/'\n",
        "train = pd.read_csv(DRIVE_FOLDER + 'train.csv')\n",
        "test = pd.read_csv(DRIVE_FOLDER + 'test.csv')\n",
        "print(\"Loaded training data, shape: \", train.shape)\n",
        "print(\"Loaded test data, shape: \", test.shape)\n",
        "print(train.head().to_string())\n",
        "\n",
        "#Check for null values\n",
        "print(train.isnull().any())\n",
        "print(test.isnull().any())\n",
        "\n",
        "#Split into features and dependent variables \n",
        "train_X = train[\"comment_text\"].values\n",
        "test_X = test[\"comment_text\"].values\n",
        "train_y = train.iloc[:, 2:].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training data, shape:  (159571, 8)\n",
            "Loaded test data, shape:  (153164, 2)\n",
            "                 id                                       comment_text  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0             0        0       0       0              0\n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0             0        0       0       0              0\n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0             0        0       0       0              0\n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0             0        0       0       0              0\n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0             0        0       0       0              0\n",
            "id               False\n",
            "comment_text     False\n",
            "toxic            False\n",
            "severe_toxic     False\n",
            "obscene          False\n",
            "threat           False\n",
            "insult           False\n",
            "identity_hate    False\n",
            "dtype: bool\n",
            "id              False\n",
            "comment_text    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRuIVaQri8N9",
        "colab_type": "code",
        "outputId": "f7f9450b-83e1-4e3e-a75d-e094258be206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing import text, sequence\n",
        "max_num_words = 30000\n",
        "tokenizer = text.Tokenizer(num_words=max_num_words)\n",
        "tokenizer.fit_on_texts(list(train_X) + list(test_X) )\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSrPGGpdfdx9",
        "colab_type": "text"
      },
      "source": [
        "Now we explore the distribution of sentence lengths so we can understand what max sentence length to set and therefore how much padding to do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkfdm27KfcVX",
        "colab_type": "code",
        "outputId": "bb558baf-a208-4337-c61b-2d9f6ab89618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sentence_lengths = [len(sentence) for sentence in train_X]\n",
        "sns.distplot(sentence_lengths);\n",
        "\n",
        "max_length = 400\n",
        "train_X = sequence.pad_sequences(train_X, maxlen=max_length)\n",
        "test_X = sequence.pad_sequences(test_X, maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBID/DxWPP0Ii2cvNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM9emExchn2Q",
        "colab_type": "text"
      },
      "source": [
        "Now we load a dictionary containing Glove embeddings of the form: {word: embedding}.  Then we create an embedding matrix that maps the words in our vocabulary to their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XIpU0FBfrkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace this line with a path to the glove embeddings file which you can download here: https://www.kaggle.com/watts2/glove6b50dtxt\n",
        "EMBEDDING_FILE = DRIVE_FOLDER + 'glove.6B.50d.txt'   \n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "max_number_words = 30000\n",
        "embedding_dimension = 50\n",
        "number_words = min(max_number_words, len(word_index))\n",
        "embedding_matrix = np.zeros((number_words, embedding_dimension))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_number_words: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjBOLsIdZSe0",
        "colab_type": "text"
      },
      "source": [
        "#2. Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1dlXquIiuQo",
        "colab_type": "text"
      },
      "source": [
        "First we create our model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa2De8Nlivx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model, activations\n",
        "from tensorflow.keras.layers import Dense, Concatenate, GRU, LSTM, SpatialDropout1D, \\\n",
        "Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Embedding\n",
        "\n",
        "gru_hidden_size = 40\n",
        "dropout_rate = 0.1\n",
        "\n",
        "class gru_model(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    Model.__init__(self)\n",
        "    self.gru = Bidirectional(GRU(units=gru_hidden_size, return_sequences=True))\n",
        "    #We use spatial dropout instead of dropout because the different dimensions of an embedding are likely to be highly correlated and so it is a more effective method of regularisation to drop whole embedding\n",
        "    #vectors at a time rather than only dropping parts of embedding vectors\n",
        "    self.spatial_dropout = SpatialDropout1D(dropout_rate) \n",
        "    self.global_avg_pooling = GlobalAveragePooling1D()\n",
        "    self.global_max_pooling = GlobalMaxPooling1D()\n",
        "    self.embedding = Embedding(max_number_words, embedding_dimension, input_length=max_length, weights=[embedding_matrix])\n",
        "    self.fc_layer = Dense(6, activation=\"sigmoid\")\n",
        "  \n",
        "  def call(self, x, training=True):\n",
        "    \"\"\"Forward pass for the network. Note that it expects input data in the form (batch, seq length, features)\"\"\"\n",
        "    x = self.embedding(x)\n",
        "    if training:\n",
        "      x = self.spatial_dropout(x)\n",
        "    x = self.gru(x)\n",
        "    avg_pool = self.global_avg_pooling(x)\n",
        "    max_pool = self.global_max_pooling(x)\n",
        "    x = Concatenate(axis=1)([avg_pool, max_pool])\n",
        "    x = self.fc_layer(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NOF_iP3m212",
        "colab_type": "text"
      },
      "source": [
        "Then we create a ROC-AUC evaluation callback because it is this crtieria that the Kaggle competition is judged on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sogwA_fgmzu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "                                          \n",
        "class ROCAUCEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRUTmuhwZbL5",
        "colab_type": "text"
      },
      "source": [
        "Then we compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2PH-o282Z9E",
        "colab_type": "code",
        "outputId": "53ef1c92-bb95-4345-e0f9-4e590926ea59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 1\n",
        "model = gru_model()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])                            \n",
        "tr_X, val_X, tr_y, val_y = train_test_split(train_X, train_y, train_size=0.95, random_state=SEED)\n",
        "rocauc = ROCAUCEvaluation(validation_data=(val_X, val_y), interval=1)\n",
        "hist = model.fit(tr_X, tr_y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_y), callbacks=[rocauc]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 151592 samples, validate on 7979 samples\n",
            "151584/151592 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9869\n",
            " ROC-AUC - epoch: 1 - score: 0.987150 \n",
            "\n",
            "151592/151592 [==============================] - 668s 4ms/sample - loss: 0.0334 - accuracy: 0.9869 - val_loss: 0.0410 - val_accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN6vuziL_ksN",
        "colab_type": "text"
      },
      "source": [
        "**Our validation set ROC-AUC is 0.987. A similar score on the test set would put us in the top 1% of Kaggle submissions as of 9/10/19**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Y-Q8V4rTYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#How to create a submission csv file for Kaggle\n",
        "submission = pd.read_csv(DRIVE_FOLDER + \"sample_submission.csv\")\n",
        "y_pred = model.predict(test_X, batch_size=1024)\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}